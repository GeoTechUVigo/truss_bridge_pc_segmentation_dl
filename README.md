# [Automated production of synthetic point clouds of truss bridges for semantic and instance segmentation using deep learning models](#TODO:engadir DOI)

Created by [Daniel Lamas Novoa](https://orcid.org/0000-0001-7275-183X), [Andrés Justo Dominguez](https://orcid.org/0000-0003-2072-4076), [Mario Soilán Rodríguez](https://orcid.org/0000-0001-6545-2225), and [Belén Riveiro Rodríguez](https://orcid.org/0000-0002-1497-4370) from [GeoTech Group](https://geotech.webs.uvigo.es/en/), [CINTECX](http://cintecx.uvigo.es/gl/), [UVigo](https://www.uvigo.gal/).

## Overview
This repository contains the code of the paper entitled Automated production of synthetic point clouds of truss bridges for semantic and instance segmentation using deep learning models](#TODO:engadir DOI)

This code is based on [JSNet](https://github.com/dlinzhao/JSNet), an artificial neural network designed to obtain semantic and instance labels from point clouds. Our work uses that architecture to segment point clouds from truss bridges. The architecture is trained with different types and quantities of synthetic truss bridges, generated by our tool [synthetic_truss_bridges](https://github.com/GeoTechUVigo/synthetic_truss_bridges).

The different models are tested on the different synthetic data and on real data.

Here are some examples of the results obtained in synthetic data:
![image1](https://github.com/GeoTechUVigo/truss_bridge_pc_segmentation_dl/blob/main/images/segmentation_dl.png)

And in real data:
![image1](https://github.com/GeoTechUVigo/truss_bridge_pc_segmentation_dl/blob/main/images/segmentation_real_u.png)

## Usage
The main code used for training and testing the models is [train_and_test.py](https://github.com/GeoTechUVigo/truss_bridge_pc_segmentation_dl/blob/main/models/JISS/train_and_test.py)

The synthetic datset used for training must be organised in folders to apply K fold cross validation.
The other synthetic datset used only for testing must be organised as the dataset used for training.
The real data must be all together in the same folder.

## Citation
If you find our work useful in your research, please consider citing:
```
@article{LAMAS2024105176,
title = {Automated production of synthetic point clouds of truss bridges for semantic and instance segmentation using deep learning models},
journal = {Automation in Construction},
volume = {158},
pages = {105176},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105176},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523004363},
author = {Daniel Lamas and Andrés Justo and Mario Soilán and Belén Riveiro},
keywords = {Point clouds, Truss bridge, Semantic segmentation, Instance segmentation, Synthetic data, Deep learning},
abstract = {The cost of obtaining large volumes of bridge data with technologies like laser scanners hinders the training of deep learning models. To address this, this paper introduces a new method for creating synthetic point clouds of truss bridges and demonstrates the effectiveness of a deep learning approach for semantic and instance segmentation of these point clouds. The method generates point clouds by specifying the dimensions and components of the bridge, resulting in high variability in the generated dataset. A deep learning model is trained using the generated point clouds, which is an adapted version of JSNet. The accuracy of the results surpasses previous heuristic methods. The proposed methodology has significant implications for the development of automated inspection and monitoring systems for truss bridges. Furthermore, the success of the deep learning approach suggests its potential for semantic and instance segmentation of complex point clouds beyond truss bridges.}
}
```

## Licence
Automated production of synthetic point clouds of truss bridges for semantic and instance segmentation using deep learning models.

Copyright (C) 2023 GeoTECH Group <geotech@uvigo.gal>

Copyright (C) 2023 Daniel Lamas Novoa <daniel.lamas.novoa@uvigo.gal>

This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or any later version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with this program in ![COPYING](https://github.com/GeoTechUVigo/truss_bridge_pc_segmentation_dl/blob/main/COPYING). If not, see <https://www.gnu.org/licenses/>.


## Data
The data real is available in the [GeoTech Group repository](https://universidadevigo-my.sharepoint.com/:f:/g/personal/geotech_uvigo_gal/EoT3-ehKcexOs0yT2zS_LpABNX2Y-rswZvqBOB5cAgtt0Q), in the folder:

```
/DataSets/trus_bridge_pc/
```

The synthetic data has been generated by using the following code with the parameters specified in article: https://github.com/GeoTechUVigo/synthetic_truss_bridges

## Instalation
The code runs in a Docker container. The specifications can be found in the file [.devcontainer](https://github.com/GeoTechUVigo/truss_bridge_pc_segmentation_dl/blob/main/.devcontainer/devcontainer.json)

The image used is: ```tensorflow/tensorflow:1.4.0-gpu-py3```
Run arguments: ```--runtime = nvidia```
Requirements installed in the container: ```pip3 install --user -r requirements.txt"```
